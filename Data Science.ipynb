{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c61d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6057846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load Dataset\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "df['target'] = data.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5857d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['target']),df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef730dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select some model to classify the particular problem and choose the best ml model.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,f1_score,precision_score,recall_score,roc_auc_score\n",
    "\n",
    "models = {'LogisticRegression': LogisticRegression(),\n",
    "         'svm': SVC(),\n",
    "          'DecisionTree': DecisionTreeClassifier(),\n",
    "           'RandomClassifier': RandomForestClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f104c5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "*******************\n",
      "y_pred :  [2 2 2 1 2 0 0 1 2 1 0 2 2 1 1 1 2 1 2 1 1 0 2 1 0 2 2 2 0 0 2 1 1 0 1 0 2\n",
      " 2]\n",
      "LogisticRegression  model_score :  0.9736842105263158\n",
      "viewing the accuracy =  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      " \n",
      "TEST PERFORMANCE:\n",
      "-----------------\n",
      "model_test_score =  0.9736842105263158\n",
      "model_test_f1_score =  0.9738118022328549\n",
      "model_test_precision =  0.9757085020242916\n",
      "svm\n",
      "*******************\n",
      "y_pred :  [2 2 2 1 2 0 0 1 2 1 0 2 2 1 1 1 2 1 2 1 1 0 2 1 0 2 2 2 0 0 2 1 1 0 1 0 2\n",
      " 2]\n",
      "svm  model_score :  0.9736842105263158\n",
      "viewing the accuracy =  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      " \n",
      "TEST PERFORMANCE:\n",
      "-----------------\n",
      "model_test_score =  0.9736842105263158\n",
      "model_test_f1_score =  0.9738118022328549\n",
      "model_test_precision =  0.9757085020242916\n",
      "DecisionTree\n",
      "*******************\n",
      "y_pred :  [2 2 2 1 2 0 0 1 2 1 0 2 2 1 1 1 2 1 2 1 1 0 2 1 0 2 2 2 0 0 2 1 1 0 1 0 2\n",
      " 2]\n",
      "DecisionTree  model_score :  0.9736842105263158\n",
      "viewing the accuracy =  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      " \n",
      "TEST PERFORMANCE:\n",
      "-----------------\n",
      "model_test_score =  0.9736842105263158\n",
      "model_test_f1_score =  0.9738118022328549\n",
      "model_test_precision =  0.9757085020242916\n",
      "RandomClassifier\n",
      "*******************\n",
      "y_pred :  [2 2 2 1 2 0 0 1 2 1 0 2 2 1 1 1 2 1 2 1 1 0 2 1 0 2 2 2 0 0 2 1 1 0 1 0 2\n",
      " 2]\n",
      "RandomClassifier  model_score :  0.9736842105263158\n",
      "viewing the accuracy =  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      " \n",
      "TEST PERFORMANCE:\n",
      "-----------------\n",
      "model_test_score =  0.9736842105263158\n",
      "model_test_f1_score =  0.9738118022328549\n",
      "model_test_precision =  0.9757085020242916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train) ## train model\n",
    "    \n",
    "    # predicted values\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Test set performance\n",
    "    model_test_accuracy = accuracy_score(y_test,y_pred)\n",
    "    model_test_f1 = f1_score(y_test,y_pred,average = 'weighted')\n",
    "    model_test_precision = precision_score(y_test,y_pred,average = 'weighted')\n",
    "    \n",
    "    #confusion matrix\n",
    "    cm = confusion_matrix(y_test,y_pred)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    print('*'*19)\n",
    "    print('y_pred : ', y_pred)\n",
    "    print(str(list(models.keys())[i])+'  model_score : ',model.score(X_test,y_test))\n",
    "    print('viewing the accuracy = ', list(y_test-y_pred))\n",
    "    print(' ')\n",
    "    print('TEST PERFORMANCE:')\n",
    "    print('-----------------')\n",
    "    print('model_test_score = ', model_test_accuracy)\n",
    "    print('model_test_f1_score = ', model_test_f1)\n",
    "    print('model_test_precision = ', model_test_precision)\n",
    "    \n",
    "    plt.suptitle('viewing accuracy using the heatmap', color = 'darkblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fc9f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
